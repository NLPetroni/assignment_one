{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural architectures for POS tagging\n",
    "###### Campardo, Chinellato, Fanti, Longhi\n",
    "###### giorgia.campardo@studio.unibo.it, diego.chinellato@studio.unibo.it, pietro.fanti@studio.unibo.it, carlo.longhi@studio.unibo.it\n",
    "##### NLP Course, AI Master's Degree, University of Bologna\n",
    "\n",
    "In this report we show an application of neural architectures trained on the Penn Treebank dataset to perform POS tagging. In particular, we show that recurrent models can be employed to achieve a performance of 0.8 in terms of average F1-score and 0.93 of accuracy on this dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    wandb = None\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Just some utility functions and constants\n",
    "PAD_TOKEN = 400000\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "classes = {'$', 'NN', ',', 'RBS', 'FW', 'CC', '#', 'VBD', 'PRP', 'RBR', 'LS', ':', 'VBZ', 'MD',\n",
    "           'EX', 'RB', 'WRB', 'NNS', 'VBG', 'PRP$', 'JJR', 'WP$', 'WP', '-LRB-', 'WDT', '``',\n",
    "           '.', 'CD', 'JJ', \"''\", 'UH', 'VBN', 'IN', 'SYM', 'DT', 'JJS', '-RRB-', 'RP', 'VB',\n",
    "           'POS', 'NNP', 'PDT', 'NNPS', 'VBP', 'TO', '<PAD>'}\n",
    "punctuation_cls = {'$', ',', '#', ':', '-LRB-', '``', '.', \"''\", 'SYM', '-RRB-', '<PAD>'}\n",
    "class2idx = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "\n",
    "def download_and_unzip(url, save_dir='.'):\n",
    "    # downloads and unzips url, if not already downloaded\n",
    "    # used for downloading dataset and glove embeddings\n",
    "    import os\n",
    "    from urllib.request import urlopen\n",
    "    from io import BytesIO\n",
    "    from zipfile import ZipFile\n",
    "    fname = url.split('/')[-1][:-4] if save_dir == '.' else save_dir\n",
    "    if fname not in os.listdir():\n",
    "        print(f'downloading and unzipping {fname}...', end=' ')\n",
    "        r = urlopen(url)\n",
    "        zipf = ZipFile(BytesIO(r.read()))\n",
    "        zipf.extractall(path=save_dir)\n",
    "        print(f'completed')\n",
    "\n",
    "def get_wandbkey():\n",
    "    with open('wandbkey.txt') as f:\n",
    "        return f.read().strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word embeddings\n",
    "We first define functions for loading glove embeddings, and for computing OOV terms embeddings based on a contextual representation: given an OOV word $w$, we define its embedding as average embedding of words appearing in the same context (sequences) as $w$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove(emb_size=100, number_token=False):\n",
    "  \"\"\"\n",
    "    Download and load glove embeddings. \n",
    "    Parameters:\n",
    "      emb_size: embedding size (50/100/200/300-dimensional vectors).    \n",
    "    Returns tuple (voc, emb) where voc is dict from words to idx (in emb) and emb is (numpy) embedding matrix\n",
    "  \"\"\"\n",
    "  n_tokens = 400000 + 1 # glove vocabulary size + PAD\n",
    "  if emb_size not in (50, 100, 200, 300):\n",
    "    raise ValueError(f'wrong size parameter: {emb_size}')\n",
    "  \n",
    "  if number_token: \n",
    "    n_tokens += 1\n",
    "  download_and_unzip('http://nlp.stanford.edu/data/glove.6B.zip', save_dir='glove')\n",
    "  vocabulary = dict()\n",
    "  embedding_matrix = np.ones((n_tokens, emb_size))\n",
    "\n",
    "  with open(f'glove/glove.6B.{emb_size}d.txt', encoding=\"utf8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embedding_matrix[i] = coefs\n",
    "        vocabulary[word] = i\n",
    "  \n",
    "  # add embedding for and padding and number token\n",
    "  if number_token:\n",
    "    embedding_matrix[n_tokens - 2] = 0\n",
    "    vocabulary['<PAD>'] = n_tokens - 2\n",
    "    digits = list(filter(lambda s: re.fullmatch('\\d+(\\.\\d*)?', s) is not None, vocabulary.keys()))\n",
    "    embedding_matrix[n_tokens - 1] = np.mean(embedding_matrix[[vocabulary[d] for d in digits]], axis=0)\n",
    "    vocabulary['<NUM>'] = n_tokens - 1\n",
    "  else: \n",
    "    embedding_matrix[n_tokens - 1] = 0\n",
    "    vocabulary['<PAD>'] = n_tokens - 1\n",
    "  return vocabulary, embedding_matrix\n",
    "\n",
    "def add_oov(start_voc, oovs, embedding_matrix, sentences, verbose=True):\n",
    "  \"\"\"\n",
    "    Computes new embedding matrix, adding embeddings for oovs\n",
    "    Parameters:\n",
    "      start_voc: dict, starting vocabulary that is extended with oovs\n",
    "      oovs: set of string, oovs to add to the starting vocabulary and embedding matrix\n",
    "      embedding_matrix: starting embedding matrix (numpy)\n",
    "      sentences: list of list of strings, set used to compute oov embeddings\n",
    "    Returns tuple (voc, emb) where voc is dict from words to idx (in emb) and emb is (numpy) embedding matrix with oovs\n",
    "  \"\"\"\n",
    "  oovs = oovs - set(start_voc.keys())\n",
    "  start_voc_size, emb_size = embedding_matrix.shape\n",
    "  oov_embeddings = np.zeros((start_voc_size + len(oovs), emb_size))\n",
    "  oov_embeddings[:start_voc_size] = embedding_matrix\n",
    "  new_voc = dict(start_voc)\n",
    "\n",
    "  for i, oov in enumerate(oovs):\n",
    "    context_words = [new_voc[word]\n",
    "                    for sentence in filter(lambda s: oov in s, sentences)\n",
    "                    for word in sentence if word in new_voc and word not in (oov, '<PAD>')]\n",
    "    if verbose and len(context_words) == 0:\n",
    "        print(f'Empty context for oov: {oov}')\n",
    "        print([sentence for sentence in filter(lambda s: oov in s, sentences)])\n",
    "    oov_embeddings[start_voc_size + i] = np.mean(oov_embeddings[context_words], axis=0)\n",
    "    new_voc[oov] = start_voc_size + i\n",
    "  return new_voc, oov_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing data\n",
    "The following function performs data preprocessing, loading documents from a given range and updating a starting vocabulary and embedding matrix with OOV embeddings. Later, in the train function, we will call load_data 3 times to build the train, validation, and test sets, iterativately (independently) updating the vocabulary and embedding matrix at each step. By default, we do not drop punctuation (although it's not considered by the evaluation metrics, it can still be useful to the model) and we split documents into individual sentences, i.e. each sequence in the preprocessed set is a sentence. We also tried to mask all numeric tokens (e.g. '12', '2021', '19.24') with a single number token '<NUM>' to make the task easier (we noticed that numeric tokens can belong to only two classes), but it turns out it hurts performances, so we dropped the idea."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(start, end, start_voc, embedding_matrix, number_token=False,\n",
    "              drop_punctuation=False, split_docs=True, ret_counts=False):\n",
    "  \"\"\"\n",
    "    Downloads dataset and preprocess dataset.\n",
    "    Params:\n",
    "      start: idx of first file to include in data\n",
    "      end: idx of last file to include in data\n",
    "      start_voc: starting vocabulary that is extended with oov terms\n",
    "      embedding_matrix: starting embedding matrix that is extended with OOV embeddings\n",
    "      number_token: if True, use a single token for all cardinal numbers\n",
    "      drop_punctuation: if True, drop punctuation\n",
    "      split_docs: if True, each sequence is one sentence; if false, each sequence is one document\n",
    "      ret_counts: if True, also return counts of each word in the documents\n",
    "    Returns tuple (inputs, labels, voc, em, [counts]) where:\n",
    "      inputs, labels are lists containing words and their respective labels\n",
    "      voc is the union of start_voc and the set of OOV terms\n",
    "      em is the updated embeddding matrix\n",
    "      (optional) counts is dict of frequencies of words in the dataset\n",
    "  \"\"\"\n",
    "  # download dataset\n",
    "  download_and_unzip('https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip')\n",
    "\n",
    "  inputs, labels = [], []\n",
    "  vocabulary = set()\n",
    "  counts = defaultdict(int)\n",
    "  \n",
    "  # build dataset\n",
    "  for doc in range(start, end+1):\n",
    "    with open(f'dependency_treebank/wsj_{doc:04d}.dp') as f:\n",
    "      \n",
    "      input_seq, label_seq = [], []\n",
    "      \n",
    "      for line in f:\n",
    "        if line.strip(): # check for empty lines\n",
    "          word, label, _ = line.split('\\t')\n",
    "          word = word.lower()\n",
    "          if '\\/' in word:\n",
    "            word = word.replace('\\/', '-')\n",
    "          if number_token and re.fullmatch('\\d+(\\.\\d*)?(\\,\\d*)?', word) is not None:\n",
    "            word = '<NUM>'\n",
    "          if not drop_punctuation or label.isalpha(): # eventually drop punctuation\n",
    "            vocabulary.add(word)\n",
    "            input_seq.append(word)\n",
    "            label_seq.append(label)\n",
    "            counts[word] += 1\n",
    "        elif split_docs: # sentence over, add to input if splitting documents\n",
    "          inputs.append(input_seq)\n",
    "          labels.append(label_seq)\n",
    "          input_seq, label_seq = [], []\n",
    "\n",
    "      # add either last sentence or whole document\n",
    "      inputs.append(input_seq)\n",
    "      labels.append(label_seq)\n",
    "\n",
    "  vocabulary, embedding_matrix = add_oov(start_voc, vocabulary, embedding_matrix, inputs)\n",
    "\n",
    "  if ret_counts:\n",
    "    return inputs, labels, vocabulary, embedding_matrix, counts\n",
    "  else:\n",
    "    return inputs, labels, vocabulary, embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batching and padding\n",
    "We define a POSDataset class, subclassing from PyTorch Dataset class, in order to use automatic batching procedures provided by the library. Moreover, we also define a custom collate function that performs padding at the batch level, thus minimizing the amount of padding tokens actually used during training w.r.t. padding the whole dataset at once before building the individual batches."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class POSDataset(torch.utils.data.Dataset):\n",
    "    \"\"\" Simple dataset class to use dataloaders (batching) \"\"\"\n",
    "    def __init__(self, inputs, labels, vocabulary):\n",
    "        self.inputs_str = inputs\n",
    "        self.labels_str = labels\n",
    "        self.voc = vocabulary\n",
    "        # map each string of the dataset into its corresponding numeric index\n",
    "        self.inputs = [[vocabulary[word] for word in sequence] for sequence in inputs]\n",
    "        self.labels = [[class2idx[label] for label in sequence] for sequence in labels]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\" Used by DataLoader to pad each batch independently \"\"\"\n",
    "    seq_lens = torch.as_tensor([len(seq[0]) for seq in batch])\n",
    "    padded_inputs = torch.nn.utils.rnn.pad_sequence([torch.as_tensor(seq[0]) for seq in batch], \n",
    "                                                     batch_first=True, padding_value=PAD_TOKEN)\n",
    "    padded_targets = torch.nn.utils.rnn.pad_sequence([torch.as_tensor(seq[1]) for seq in batch], \n",
    "                                                     batch_first=True, padding_value=class2idx['<PAD>'])\n",
    "    return padded_inputs, padded_targets, seq_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model definition\n",
    "The POSTagger class contains the implementation of the four considered neural architectures. The baseline $LSTM\\_1L$ is composed by a LSTM layer followed by a Linear layer; the three variations are $LSTM\\_2L$, which features two LSTM layers; $GRU$, which uses one GRU layer rather than LSTM, and $FC\\_2L$ which is made of a single LSTM layer followed by two linear layers with a ReLU in between the two (otherwise the model would be equivalent to $LSTM\\_1L$).\n",
    "We also implemented an initialization trick where we set the bias of the forget (reset) gate of the LSTM (GRU) layers to 1 (-1); this is because sometimes it can take a while for RNNs to learn to remember information form the last time step, thus we make them remember more by default.\n",
    "\n",
    "We also implemented a custom Focal Loss (a variation of cross entropy originally used to train CNNs for object detection) to tackle the problem of class imbalance that is present in the Penn Treebank dataset that we are using, but it didn't appear to be really useful so we later switched to a simpler weighted cross entropy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSTagger(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, embedding_matrix, type, rec_size=1, units=None, hid_size=64):\n",
    "    \"\"\"\n",
    "      A recurrent network performing multiclass classification (POS tagging).\n",
    "      Params:\n",
    "        type: type of rnn, either 'lstm' or 'gru'\n",
    "        embedding_matrix: embedding matrix for embedding layer\n",
    "        rec_size: number of stacked recurrent modules\n",
    "        units: int or None, if given then add one additional linear layer with given number of units\n",
    "        hid_size: size of hidden state of recurrent module\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    emb_size = embedding_matrix.shape[1]\n",
    "    self.emb_layer = nn.Embedding.from_pretrained(torch.as_tensor(embedding_matrix))\n",
    "\n",
    "    # build recurrent layer(s)\n",
    "    if type == 'lstm':\n",
    "      self.rec_modules = nn.LSTM(input_size=emb_size, hidden_size=hid_size, bidirectional=True,\n",
    "                                 batch_first=True, num_layers=rec_size)\n",
    "    elif type == 'gru':\n",
    "      self.rec_modules = nn.GRU(input_size=emb_size, hidden_size=hid_size, bidirectional=True,\n",
    "                                batch_first=True, num_layers=rec_size)\n",
    "    else:\n",
    "      raise ValueError(f'wrong type {type}, either lstm or gru')\n",
    "    self._rec_init(type)\n",
    "\n",
    "    # build linear layer(s)\n",
    "    self.fc_modules = nn.Sequential(nn.Linear(2 * hid_size, units if units is not None else len(classes)))\n",
    "    if units is not None:\n",
    "      self.fc_modules.add_module('fc1_relu', nn.ReLU())\n",
    "      self.fc_modules.add_module('fc2', nn.Linear(units, len(classes)))\n",
    "\n",
    "\n",
    "  def forward(self, x, seq_lens):\n",
    "    embed_vecs = self.emb_layer(x).float()\n",
    "    packed_vecs = torch.nn.utils.rnn.pack_padded_sequence(embed_vecs, seq_lens, batch_first=True, enforce_sorted=False)\n",
    "    rec_out, _ = self.rec_modules(packed_vecs)\n",
    "    unpacked_rec_out, _ = torch.nn.utils.rnn.pad_packed_sequence(rec_out, batch_first=True, padding_value=PAD_TOKEN)\n",
    "    fc_out = self.fc_modules(unpacked_rec_out)\n",
    "    return fc_out\n",
    "\n",
    "  def _rec_init(self, type):\n",
    "      # initialization trick for making the RNN more \"forgetful\" at the beginning of training\n",
    "      for names in self.rec_modules._all_weights:\n",
    "        for name in filter(lambda n: \"bias\" in n,  names):\n",
    "            bias = getattr(self.rec_modules, name)\n",
    "            n = bias.size(0)\n",
    "            if type == 'lstm': # init lstm forget gate bias to 1\n",
    "                start, end = n//4, n//2\n",
    "                bias.data[start:end].fill_(1.)\n",
    "            else: # init gru reset gate bias to -1\n",
    "                end = n//3\n",
    "                bias.data[:end].fill_(-1.)\n",
    "\n",
    "# Tried but not so useful\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, ignore_index=-100, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "        self.ignore_index = ignore_index\n",
    "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=self.ignore_index, reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets): \n",
    "        ce_loss = self.loss_fn(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training procedure\n",
    "In the following cells, we define functions for training the network for one epoch on the training set and for performing evaluation on the validation (or testing) set. We also implemented a EarlyStopping class that saves model checkpoints while keeping track of a score (we use the validation loss) to check for early stopping."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience, model, delta=0, path='res'):\n",
    "        \"\"\" Implements early stopping.\n",
    "            Params:\n",
    "                patience: int, number of epochs without score improvement before early stopping\n",
    "                model: torch.nn.Module that is being trained\n",
    "                delta: float, minimum change in score to detect improvement\n",
    "                path: str, path to save checkpoints\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.model = model\n",
    "        self.path = path\n",
    "        if not os.path.isdir(self.path):\n",
    "            os.mkdir(self.path)\n",
    "        self.best_score = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def step(self, epoch, score):\n",
    "        \"\"\" Updates ES tracker after one epoch.\n",
    "            Params:\n",
    "                epoch: current epoch\n",
    "                score: validation loss\n",
    "            Returns tuple (stop, checkpoint),\n",
    "                where stop is True if early stopping has occurred and False otherwise,\n",
    "                and checkpoint is last best checkpoint\n",
    "        \"\"\"\n",
    "        if score < self.best_score:\n",
    "            # print('Validation loss decreasing, storing new checkpoint')\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            checkpoint = {'model': self.model.state_dict(), 'epoch': epoch}\n",
    "            torch.save(checkpoint, 'res/checkpoint.pth')\n",
    "            return False, checkpoint\n",
    "        elif abs(score - self.best_score) > self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f'Early stopping occured at epoch {epoch} with patience {self.patience}')\n",
    "                checkpoint = torch.load('res/checkpoint.pth', map_location='cpu')\n",
    "                return True, checkpoint\n",
    "            if self.counter == (self.patience//2):\n",
    "                print(f'Validation loss increasing for {self.counter} epochs')\n",
    "        return False, None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, loss_fn, data_loader, device):\n",
    "    \"\"\" \n",
    "        Trains model for one epoch on the given dataloader.\n",
    "        Parameters:\n",
    "            model: torch.nn.Module to train\n",
    "            optimizer: torch.optim optimizer object\n",
    "            loss_fn: torch.nn criterion to use to compute loss, given outputs and targets\n",
    "            data_loader: torch.utils.data.DataLoader \n",
    "            device: torch.device where training is performed\n",
    "        Returns log dict {'train/loss' : list(loss values for each batch)} \n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    log_dict = {'train/loss': []}\n",
    "\n",
    "    for inputs, targets, seq_lens in data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        scores = model(inputs, seq_lens).transpose(1, 2)\n",
    "        loss = loss_fn(scores, targets)\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(f\"Loss is {loss_value}, stopping training\")\n",
    "            exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        log_dict['train/loss'].append(loss_value)\n",
    "\n",
    "    return log_dict\n",
    "\n",
    "def evaluate(model, loss_fn, data_loader, device, split, ret_f1_classes=False):\n",
    "    \"\"\" \n",
    "        Evaluate model on the given dataloader.\n",
    "        Parameters:\n",
    "            model: torch.nn.Module to evaluate\n",
    "            loss_fn: torch.nn criterion to use to compute loss, given outputs and targets\n",
    "            data_loader: torch.utils.data.DataLoader \n",
    "            device: torch.device where evaluation is performed\n",
    "            split: either 'valid' or 'test'\n",
    "            ret_f1_classes: if True, also returns per-class f1 scores\n",
    "        Returns log dict {'valid/loss' : mean loss, 'valid/{metric}': mean metric} \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    assert len(data_loader) == 1 # must be a single batch\n",
    "    with torch.no_grad():\n",
    "        inputs, targets, seq_lens = next(iter(data_loader))\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        scores = model(inputs, seq_lens).transpose(1, 2)\n",
    "        losses = loss_fn(scores, targets).item()\n",
    "        preds = torch.argmax(scores, 1)\n",
    "\n",
    "        targets = targets.cpu().numpy()\n",
    "        preds = preds.cpu().numpy()\n",
    "        mask = [targets != class2idx[c] for c in punctuation_cls]\n",
    "        mask = np.array(reduce(lambda a,b: a & b, mask)).reshape(targets.shape)\n",
    "        acc = np.where(mask, targets==preds, False).sum() / mask.sum()\n",
    "        cls = [class2idx[c] for c in (classes - punctuation_cls)]\n",
    "        f1_classes = f1_score(targets.reshape(-1), preds.reshape(-1),\n",
    "                      labels=cls, average=None, zero_division=0)\n",
    "\n",
    "    log_dict = {f'{split}/loss': losses,\n",
    "                f'{split}/accuracy': acc,\n",
    "                f'{split}/f1': np.mean(f1_classes)}\n",
    "    if ret_f1_classes:\n",
    "        return log_dict, {c:s for c,s in zip(cls, f1_classes)}\n",
    "    else:\n",
    "        return log_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main training loop\n",
    "We finally define one function that fully trains one model. While performing tuning/model selection, we train on the training set and evaluate (every epoch) on the validation set; for the last two runs (test=True), we train on the big train + validation set and evaluate only once on the test set at the end of training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg, tags=None, verbose=False, test=False, emb_size=100, number_token=False, weighted_ce=False, use_wandb=False):\n",
    "    \"\"\" Fully trains one model, based on cfg parameters, on training set and performs evaluation on validation set.\n",
    "        Params:\n",
    "            cfg: parameter for training\n",
    "            tags: list of str, wandb tags\n",
    "            verbose: bool, if True verbose output\n",
    "            test: if False, train on train set and evaluate at each epoch on the validation set;\n",
    "                  if True, tra on train + validation set and evaluate on test set once at the end of training\n",
    "            emb_size: one of (50, 100, 200, 300), size of embedding representation\n",
    "            number_token: bool, if True use number token for numeric strings\n",
    "            weigthed_ce: bool, if True use weighted cross entropy\n",
    "            use_wandb: bool, if True enables wandb logging\n",
    "        Returns trained model and wandb run\n",
    "    \"\"\"\n",
    "    idx2classes = {i: c for c, i in class2idx.items()}\n",
    "    cfg_dict = {\n",
    "        'epochs': cfg['EPOCHS'], 'batch_size': cfg['BATCH_SIZE'], 'number_token': number_token,\n",
    "        'model': cfg['TYPE'], 'rec_size': cfg['REC_SIZE'], 'units': cfg['UNITS'], 'hid_size': cfg['HID_SIZE'],\n",
    "        'optim': cfg['OPTIM'], 'lr': cfg['LR'], 'alpha': cfg['ALPHA'], 'betas': cfg['BETAS'], 'momentum': cfg['MOMENTUM'],\n",
    "        'weighted_ce': weighted_ce, 'emb_size': emb_size\n",
    "    }\n",
    "    if verbose:\n",
    "        print('CONFIG PARAMETERS:')\n",
    "        pprint(cfg_dict)\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.login(key=get_wandbkey())\n",
    "        run = wandb.init(project=\"assignment-one\", entity=\"nlpetroni\", group=f'{\"testing\" if test else \"validation\"}',\n",
    "                        reinit=True, config=cfg_dict, tags=tags)\n",
    "        wandb.define_metric(\"train_step\")\n",
    "        wandb.define_metric(\"epoch\")\n",
    "        wandb.define_metric('train/loss', step_metric=\"train_step\", summary=\"min\")\n",
    "        wandb.define_metric(f\"valid/loss\", step_metric=\"epoch\", summary=\"min\")\n",
    "        wandb.define_metric(f\"valid/accuracy\", step_metric=\"epoch\", summary=\"max\")\n",
    "        wandb.define_metric(f\"valid/f1\", step_metric=\"epoch\", summary=\"max\")\n",
    "        wandb.define_metric(f\"test/accuracy\", step_metric=\"epoch\", summary=\"max\")\n",
    "        wandb.define_metric(f\"test/f1\", step_metric=\"epoch\", summary=\"max\")\n",
    "    else:\n",
    "        run = None\n",
    "\n",
    "    glove_voc, embedding_matrix = get_glove(number_token=number_token, emb_size=emb_size)\n",
    "    if not test:\n",
    "        split = 'valid'\n",
    "        train_set, train_labels, train_voc, embedding_matrix = load_data(1, 100, glove_voc, embedding_matrix, number_token=number_token, drop_punctuation=False)\n",
    "        valid_set, valid_labels, valid_voc, embedding_matrix = load_data(101, 150, train_voc, embedding_matrix, number_token=number_token, drop_punctuation=False)\n",
    "        train_ds = POSDataset(train_set, train_labels, train_voc)\n",
    "        valid_ds = POSDataset(valid_set, valid_labels, valid_voc)\n",
    "        train_dl = torch.utils.data.DataLoader(train_ds, batch_size=cfg['BATCH_SIZE'], collate_fn=collate_fn, shuffle=True)\n",
    "        valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=len(valid_ds), collate_fn=collate_fn)\n",
    "    else:\n",
    "        split = 'test'\n",
    "        train_set, train_labels, train_voc, embedding_matrix = load_data(1, 150, glove_voc, embedding_matrix, number_token=number_token, drop_punctuation=False)\n",
    "        test_set, test_labels, test_voc, embedding_matrix = load_data(151, 199, train_voc, embedding_matrix, number_token=number_token, drop_punctuation=False)\n",
    "        train_ds = POSDataset(train_set, train_labels, train_voc)\n",
    "        test_ds = POSDataset(test_set, test_labels, test_voc)\n",
    "        train_dl = torch.utils.data.DataLoader(train_ds, batch_size=cfg['BATCH_SIZE'], collate_fn=collate_fn, shuffle=True)\n",
    "        test_dl = torch.utils.data.DataLoader(test_ds, batch_size=len(test_ds), collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "    model = POSTagger(embedding_matrix, type=cfg['TYPE'], rec_size=cfg['REC_SIZE'], units=cfg['UNITS'], hid_size=cfg['HID_SIZE']).to(device)\n",
    "    if use_wandb:\n",
    "        wandb.watch(model, log_graph=True)\n",
    "    if verbose:\n",
    "        print(summary(model))\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    if cfg[\"OPTIM\"] == 'rmsprop':\n",
    "        optimizer = torch.optim.RMSprop(params, lr=cfg['LR'], alpha=cfg['ALPHA'], momentum=cfg['MOMENTUM'], weight_decay=cfg['WEIGHT_DECAY'])\n",
    "    elif cfg[\"OPTIM\"] == 'adam':\n",
    "        optimizer = torch.optim.Adam(params, lr=cfg['LR'], betas=cfg['BETAS'], weight_decay=cfg['WEIGHT_DECAY'])\n",
    "    else:\n",
    "        raise ValueError(f'wrong optim {cfg[\"OPTIM\"]}, either rmsprop or adam')\n",
    "\n",
    "    if weighted_ce:\n",
    "        cls, counts = np.unique([w for s in train_labels for w in s], return_counts=True)\n",
    "        weights = torch.ones(len(classes))\n",
    "        for c,n in zip(cls, counts):\n",
    "            if n <= 150 and c not in punctuation_cls:\n",
    "                weights[class2idx[c]] += 1-(n/150)\n",
    "        weights[class2idx['<PAD>']] = 0\n",
    "        weights = (weights - weights.min())/(weights.max()-weights.min())\n",
    "        weights = weights.to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss(ignore_index=class2idx['<PAD>'], weight=weights)\n",
    "    else:\n",
    "        loss_fn = nn.CrossEntropyLoss(ignore_index=class2idx['<PAD>'])\n",
    "\n",
    "    train_step = 0\n",
    "    es_tracker = EarlyStopping(20, model)\n",
    "    epoch = 0\n",
    "    stop = False\n",
    "    print('STARTING TRAINING')\n",
    "\n",
    "    while epoch < cfg['EPOCHS'] and not stop:\n",
    "        train_log_dict = train_one_epoch(model, optimizer, loss_fn, train_dl, device)\n",
    "        if not test:\n",
    "            valid_log_dict, f1_classes = evaluate(model, loss_fn, valid_dl, device, split=split, ret_f1_classes=True)\n",
    "            stop, checkpoint = es_tracker.step(epoch, valid_log_dict['valid/loss'])\n",
    "            if use_wandb:\n",
    "                wandb.log({'epoch': epoch, 'valid/loss': valid_log_dict['valid/loss'],\n",
    "                        'valid/accuracy': valid_log_dict['valid/accuracy'], 'valid/f1': valid_log_dict['valid/f1'],\n",
    "                        'valid/f1_distribution': wandb.Histogram(np_histogram=np.histogram(list(f1_classes.values())))})\n",
    "            if stop:\n",
    "                model.load_state_dict(checkpoint['model'])\n",
    "                # re evaluate on the best checkpoint for loggin purposes\n",
    "                valid_log_dict, f1_classes = evaluate(model, loss_fn, valid_dl, device, split=split, ret_f1_classes=True)\n",
    "            if (epoch % 25) == 0:\n",
    "                print(f'[{epoch:03d}/{cfg[\"EPOCHS\"]:03d}] train loss: {np.mean(train_log_dict[\"train/loss\"]):.3f}, valid loss: {valid_log_dict[\"valid/loss\"]:.3f}, f1: {valid_log_dict[\"valid/f1\"]:.2f} accuracy: {valid_log_dict[\"valid/accuracy\"]:.2f}')\n",
    "        if use_wandb:\n",
    "            for batch_loss in train_log_dict['train/loss']:\n",
    "                wandb.log({'train_step': train_step, 'epoch': epoch, 'train/loss': batch_loss})\n",
    "                train_step += 1\n",
    "        epoch += 1\n",
    "\n",
    "    # log per-class f1 scores\n",
    "    if not test:\n",
    "        data = [[idx2classes[i], score] for i, score in f1_classes.items()]\n",
    "        table = wandb.Table(data=data, columns=[\"class\", \"f1_score\"])\n",
    "        wandb.log({'valid/f1_per_class': wandb.plot.bar(table, \"class\", \"f1_score\", title=\"F1 per class bar chart\")})\n",
    "    else:\n",
    "        log_dict, f1_classes = evaluate(model, loss_fn, test_dl, device, split=split, ret_f1_classes=True)\n",
    "        data = [[idx2classes[i], score] for i,score in f1_classes.items()]\n",
    "        table = wandb.Table(data=data, columns = [\"class\", \"f1_score\"])\n",
    "        wandb.log({'test/loss': log_dict['test/loss'], 'test/accuracy': log_dict['test/accuracy'], 'test/f1': log_dict['test/f1'],\n",
    "                   'test/f1_per_class': wandb.plot.bar(table, \"class\", \"f1_score\", title=\"F1 per class bar chart\")})\n",
    "        print(f\"TEST SET METRICS \\nloss: {log_dict['test/loss']:.3f}, accuracy: {log_dict['test/accuracy']:.2f}, f1: {log_dict['test/f1']:.1f}\")\n",
    "    \n",
    "    if use_wandb:\n",
    "        run.finish()\n",
    "\n",
    "    return model, run\n",
    "\n",
    "def fix_random(seed):\n",
    "    \"\"\"Fix all the possible sources of randomness\n",
    "        Params:\n",
    "        seed: the seed to use\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "cfg = {'EPOCHS': 200, 'BATCH_SIZE': 32, 'TYPE': 'lstm', 'REC_SIZE': 1, 'UNITS': None, 'HID_SIZE': 64, 'OPTIM': 'rmsprop', 'LR': 2.53-4, 'ALPHA': 0.95, 'MOMENTUM': 0.5, 'BETAS': (0.9, 0.999), 'WEIGHT_DECAY': 0}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping tuning, see https://wandb.ai/nlpetroni/assignment-one to view the tuning results\n",
      "Set tuning = True to perform tuning\n"
     ]
    }
   ],
   "source": [
    "use_wandb = False\n",
    "fix_random(42)\n",
    "tuning = False\n",
    "if tuning: # takes a while to run, see https://wandb.ai/nlpetroni/assignment-one for results\n",
    "    for (tag, type, rec_size, units) in (('lstm_1L', 'lstm', 1, None), ('lstm_2L', 'lstm', 2, None),\n",
    "                                         ('fc_2L', 'lstm', 1, 128), ('gru', 'gru', 1, None)):\n",
    "        for wce in (True, False):\n",
    "            for lr in (1e-3, 7.5e-4, 2.5e-4, 1e-4):\n",
    "                cfg['TYPE'] = type\n",
    "                cfg['REC_SIZE'] = rec_size\n",
    "                cfg['LR'] = lr\n",
    "                cfg['UNITS'] = units\n",
    "                _, run = train(cfg=cfg, tags=['tuning', tag], weighted_ce=wce, use_wandb=use_wandb)\n",
    "else:\n",
    "    print(f'Skipping tuning, see https://wandb.ai/nlpetroni/assignment-one to view the tuning results')\n",
    "    print('Set tuning = True to perform tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/2obovfzv\" target=\"_blank\">dry-shadow-1374</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-one\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/200] train loss: 2.327, valid loss: 1.593, f1: 0.22 accuracy: 0.57\n",
      "[025/200] train loss: 0.086, valid loss: 0.277, f1: 0.79 accuracy: 0.91\n",
      "Validation loss increasing for 10 epochs\n",
      "Early stopping occured at epoch 41 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 7604... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.76092233009…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec81e8802dd5481eb53e4225a7023f49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>▁▄▆▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>valid/f1</td><td>▁▃▄▅▆▆▆▆▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>valid/loss</td><td>█▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>41</td></tr><tr><td>train_step</td><td>2603</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">dry-shadow-1374</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/2obovfzv\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-one/runs/2obovfzv</a><br/>\nFind logs at: <code>./wandb/run-20211218_195621-2obovfzv/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/1fzfo2bm\" target=\"_blank\">snowy-sea-1375</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-one\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/200] train loss: 2.466, valid loss: 1.654, f1: 0.19 accuracy: 0.54\n",
      "Validation loss increasing for 10 epochs\n",
      "[025/200] train loss: 0.018, valid loss: 0.355, f1: 0.79 accuracy: 0.91\n",
      "Early stopping occured at epoch 33 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 7693... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "890cc43a1fd14d72b80bb68559de62f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>█▆▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>▁▄▆▇▇▇████████████████████████████</td></tr><tr><td>valid/f1</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>valid/loss</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>33</td></tr><tr><td>train_step</td><td>2107</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">snowy-sea-1375</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/1fzfo2bm\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-one/runs/1fzfo2bm</a><br/>\nFind logs at: <code>./wandb/run-20211218_195718-1fzfo2bm/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/2ipsqyiq\" target=\"_blank\">elated-wind-1376</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-one\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/200] train loss: 2.914, valid loss: 2.563, f1: 0.04 accuracy: 0.30\n",
      "[025/200] train loss: 0.232, valid loss: 0.343, f1: 0.70 accuracy: 0.89\n",
      "Validation loss increasing for 10 epochs\n",
      "[050/200] train loss: 0.093, valid loss: 0.315, f1: 0.75 accuracy: 0.90\n",
      "Early stopping occured at epoch 60 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 7807... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.78201151971…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a8096e3c49e44ddbffb3095da2cbe38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>▁▃▅▆▇▇▇▇████████████████████████████████</td></tr><tr><td>valid/f1</td><td>▁▂▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇████████████████████</td></tr><tr><td>valid/loss</td><td>█▆▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>60</td></tr><tr><td>train_step</td><td>3781</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">elated-wind-1376</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/2ipsqyiq\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-one/runs/2ipsqyiq</a><br/>\nFind logs at: <code>./wandb/run-20211218_195816-2ipsqyiq/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/2s3zd62u\" target=\"_blank\">dark-universe-1377</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-one\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/200] train loss: 1.837, valid loss: 1.030, f1: 0.37 accuracy: 0.72\n",
      "[025/200] train loss: 0.048, valid loss: 0.295, f1: 0.77 accuracy: 0.91\n",
      "Validation loss increasing for 10 epochs\n",
      "Early stopping occured at epoch 38 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 7875... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb50a515e68b471dbdb09a332567fa92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>▁▄▆▆▇▇▇▇███████████████████████████████</td></tr><tr><td>valid/f1</td><td>▁▃▅▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>valid/loss</td><td>█▅▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>38</td></tr><tr><td>train_step</td><td>2417</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">dark-universe-1377</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/2s3zd62u\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-one/runs/2s3zd62u</a><br/>\nFind logs at: <code>./wandb/run-20211218_195944-2s3zd62u/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_wandb = True\n",
    "fix_random(42)\n",
    "for (tag, type, rec_size, units, lr, wl) in (('lstm_1L', 'lstm', 1, None, 7.5e-4, True),\n",
    "                                            ('lstm_2L', 'lstm', 2, None, 1e-3, True),\n",
    "                                            ('fc_2L', 'lstm', 1, 128, 2.5e-4, True),\n",
    "                                            ('gru', 'gru', 1, None, 7.5e-4, True)):\n",
    "    cfg['TYPE'] = type\n",
    "    cfg['REC_SIZE'] = rec_size\n",
    "    cfg['LR'] = lr\n",
    "    cfg['UNITS'] = units\n",
    "    _, run = train(cfg, tags=['model selection', tag], weighted_ce=wl, use_wandb=use_wandb)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final evaluation of the two best architectures on the testing set\n",
    "The two best performing architectures, based on evaluation on the validation set, appear to be $LSTM\\_1L$ and $LSTM\\_2L$, i.e. LSTM-based architectures. In this last cell, we retrain these two architectures on the train + validation set and perform evaluation on the testing set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/qbilwiyg\" target=\"_blank\">dandy-snowball-1378</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-one\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "TEST SET METRICS \n",
      "loss: 0.259, accuracy: 0.93, f1: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 8009... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bac9e2eba0748bbae73b2c26d35431d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>train/loss</td><td>█▅▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>40</td></tr><tr><td>test/loss</td><td>0.25912</td></tr><tr><td>train_step</td><td>4181</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">dandy-snowball-1378</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/qbilwiyg\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-one/runs/qbilwiyg</a><br/>\nFind logs at: <code>./wandb/run-20211218_200354-qbilwiyg/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/2dpgfi4u\" target=\"_blank\">ethereal-sky-1379</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-one\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "TEST SET METRICS \n",
      "loss: 0.308, accuracy: 0.93, f1: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 8064... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82d3562f0eaf4967989f1a2711fe4d0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>train/loss</td><td>█▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>32</td></tr><tr><td>test/loss</td><td>0.30819</td></tr><tr><td>train_step</td><td>3365</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">ethereal-sky-1379</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-one/runs/2dpgfi4u\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-one/runs/2dpgfi4u</a><br/>\nFind logs at: <code>./wandb/run-20211218_200439-2dpgfi4u/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_wandb = True\n",
    "fix_random(42)\n",
    "# first best model\n",
    "cfg['EPOCHS'] = 41\n",
    "cfg['TYPE'] = 'lstm'\n",
    "cfg['LR'] = 7.5e-4\n",
    "cfg['REC_SIZE'] = 1\n",
    "cfg['UNITS'] = None\n",
    "lstm_1l, _ = train(cfg, tags=['test', 'lstm_1L'], test=True, weighted_ce=True, use_wandb=use_wandb)\n",
    "torch.save({'model': lstm_1l.state_dict()}, 'res/models/lstm_1l.pth')\n",
    "# second best model\n",
    "cfg['EPOCHS'] = 33\n",
    "cfg['TYPE'] = 'lstm'\n",
    "cfg['LR'] = 1e-3\n",
    "cfg['REC_SIZE'] = 2\n",
    "lstm_2l, _ = train(cfg, tags=['test', 'lstm_2L'], test=True, weighted_ce=True, use_wandb=use_wandb)\n",
    "torch.save({'model': lstm_2l.state_dict()}, 'res/models/lstm_2l.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion and error analysis\n",
    "*Note: to look at the plots please click [here](https://wandb.ai/nlpetroni/assignment-one/reports/Results--VmlldzoxMzU2NDU4?accessToken=fyze87urj6r5b2ok4p9xnfu26ouwmu7pkmge1yw838z07ohxtyf9mdla5n13s6fr)*\n",
    "\n",
    "Given the plots of the F1 score per class on the validation set of the best two models, it is clear that all the models aren’t able to classify correctly token with the tags FW and UH due to the fact that there aren’t many examples of these two classes in the dataset (UH has only 3 examples in train + validation set, while FW has only 4). Test performances on these two classes cannot be evaluated as there are no examples on the test set. Other tags that have poor performances in the validation are LS, WP\\$, PDT, NNPS, even though they’re variable among different models. LS, WP\\$ and PDT are three underrepresented tags, the first is not even present in the test set, the second has only 4 examples in the test set out of 14, the third has only 4 examples in the test set out of 23 total examples. One motivation behind the poor performances on the NNPS(plural proper nouns) tag is that it doesn’t have as many examples as its singular counterpart NNP(singular proper nouns). Moreover, plenty of the NNPS tagged words are probably OOVs and contextual embeddings may not be the best embedding for such words. One possibly better way to address this issue could be to take into consideration the embedding of their singular counterpart in NNP, if present in the vocabulary, in computing its contextual embedding. Results on the test set partially confirm performances and findings discussed above: the NNPS tag has a good improvement on the test performances, but still has a F1 score below 0.5; the baseline model (the best, LSTM 1L) is able to improve performances from validation to test on several classes like PDT, NNPS and RBS. The second best model (LSTM 2L) seems more flawed: it is able to improve some of the poor performances on tags WP$, NNPS, RBS at the expense of the simple TO tag that had a F1 score of 0.99 in validation which drastically drops to 0.03 in the test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d92e98c3664063ec1b567951c01aa42f8ffade76e6df5a130cb26ea124003d56"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
